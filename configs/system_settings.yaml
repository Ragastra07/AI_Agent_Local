default_model: "ollama_mistral"
temperature: 0.7
max_tokens: 2048
